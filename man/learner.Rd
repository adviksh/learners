% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner_class.R, R/learner_methods.R
\name{learner}
\alias{learner}
\alias{make_learner}
\alias{tune.learner}
\alias{train.learner}
\alias{predict.learner}
\alias{tune_predict_ins.learner}
\alias{tune_predict_oos.learner}
\alias{tune_predict_oos_fold.learner}
\title{Learner Class}
\usage{
make_learner(name = NULL, tune_fun = NULL, train_fun = NULL,
  model = NULL, predict_fun = stats::predict)

\method{tune}{learner}(object, features, tgt, wt = NULL, tune_folds, ...)

\method{train}{learner}(object, features, tgt, wt = NULL, ...)

\method{predict}{learner}(object, newdata, ...)

\method{tune_predict_ins}{learner}(object, features, tgt, wt = NULL,
  tune_folds, ...)

\method{tune_predict_oos}{learner}(object, features, tgt, wt = NULL,
  tune_folds, ...)

\method{tune_predict_oos_fold}{learner}(object, features, tgt, wt = NULL,
  tune_folds, which_fold, ...)
}
\arguments{
\item{name}{A name for the learner.}

\item{tune_fun}{A tuning function.}

\item{train_fun}{A training function.}

\item{model}{A trained model.}

\item{predict_fun}{A prediction function.}

\item{object}{(learner) A learner object, as created by make_learner()}

\item{features}{(numeric matrix)}

\item{tgt}{(vector)}

\item{wt}{(nonnegative vector)}

\item{tune_folds}{(integer vector)}

\item{...}{further arguments passed to or from other methods}

\item{newdata}{(matrix) A dataset to form predictions form.}

\item{which_fold}{(integer)}
}
\description{
learners represents predictive models with the \code{learner} class.
A learner has four components: a tuning function, a training function,
a fitted model object, and a prediction function. \code{make_learner} is a
utility for creating new learners. You'll need a tuning function and a
prediction function to create a new learner. The training function and
fitted model usually depend on the dataset, so you don't need them to
create a learner.
}
\details{
The tune, train, and predict functions take only data as arguments. This
means they do not not accept parameters or hyperparameters as inputs.
Instead, all parameters and hyperparameters must be defined inside these
functions. Specifically:

The tuning function takes (\code{features}, \code{tgt}, \code{wt}, and \code{folds})
as arguments, and returns a training function. These exact names must be
used for the arguments in this exact order. If hyperparameters need
to be set, they should be baked into the resulting training function. For
example, a tuning function for penalized regression could use
cross-validation over the provided \code{folds} to choose a penalty parameter,
and then return a training function that estimates a regression model
with the chosen penalty.

The training function takes (\code{features}, \code{tgt}, \code{wt}) as arguments
and returns a fitted model object. These exact names must be
used for the arguments in this exact order. If any parameters need to be set,
they should be baked into the fitted model object. For example, a training
function for a regression model should estiamte all necessary coefficients
and store them in a fitted model so that \code{predict} can access them
later.

The prediction function takes (\code{fitted_model}, \code{features}) as arguments
and returns predicted values. You can name the arguments as you'd like, but
they must appear in this exact order. The returned predictions should be
the probability of being in the positive class for binary classification,
continuous predictions for regression, and a matrix of class probabilities
(one column per class) for multiclass classification.
}
